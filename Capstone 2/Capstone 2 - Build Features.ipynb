{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KAGGLE DS & ML SURVEY - 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESSING THE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.axes._axes.Axes.hlines(self, y, xmin, xmax, colors=None, linestyles='solid', label='', *, data=None, **kwargs)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.colors\n",
    "matplotlib.colors.rgb_to_hsv\n",
    "matplotlib.colors.to_rgba\n",
    "matplotlib.figure.Figure.get_size_inches\n",
    "matplotlib.figure.Figure.subplots_adjust\n",
    "matplotlib.axes.Axes.text\n",
    "matplotlib.axes.Axes.hlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle launches a Data Science and Machine Learning (DS & ML) Survey every year as a way to learn about the DS field, with questions on the user demographics (age, gender, education level, working status), their data science and machine learning knowledge and experience, and methods and tools they use or would like to get familiar with. The survey was distributed to the entire Kaggle community through the Kaggle (opted-in) email list, and promoted on the Kaggle website and Kaggle Twitter channel. Since it only targets the Kaggle community, everyone answering has some level of involvement with Kaggle. However, there is much diversity among the Kaggle community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='C:\\\\Users\\\\l_gas\\\\Documents\\\\Data\\\\Kaggle ML and DS Survey\\\\2020\\\\original_data\\\\'\n",
    "survey_data=datapath+\"kaggle_survey_2020_responses.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv(survey_data,header=None,skiprows=2)\n",
    "col_names = list(pd.read_csv(survey_data,nrows=1,header=None).values)[0]\n",
    "survey.columns = col_names\n",
    "survey['Id']=survey.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Levels - Range Mid points\n",
      "29.0    4011\n",
      "24.0    3786\n",
      "21.0    3469\n",
      "34.0    2811\n",
      "39.0    1991\n",
      "44.0    1397\n",
      "49.0     988\n",
      "54.0     698\n",
      "59.0     411\n",
      "69.0     398\n",
      "Name: age_lev, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    19960.000000\n",
       "mean        32.692285\n",
       "std         11.116358\n",
       "min         21.000000\n",
       "25%         24.000000\n",
       "50%         29.000000\n",
       "75%         39.000000\n",
       "max         69.000000\n",
       "Name: age_lev, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age groups (midpoints)\n",
    "age_b = pd.DataFrame({'Q1_lb_age': [], 'Q1_ub_age': []})\n",
    "aa = survey.Q1.str.lstrip('+')\n",
    "age_b[['Q1_lb_age','Q1_ub_age']] = aa.str.split('-',expand=True)\n",
    "age_lev = pd.Series(pd.to_numeric(age_b.Q1_ub_age)+(pd.to_numeric(age_b.Q1_ub_age) - pd.to_numeric(age_b.Q1_ub_age))/2,name='age_lev')\n",
    "\n",
    "print(\"Age Levels - Range Mid points\")\n",
    "print(age_lev.value_counts())\n",
    "print(type(age_lev))\n",
    "age_lev.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Levels: 1-HS or less 2=Some College 3=BA 4=MA 5=PhD\n",
      "4    7859\n",
      "3    6978\n",
      "5    3001\n",
      "2    1092\n",
      "1     240\n",
      "Name: educ, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     19170\n",
       "unique        5\n",
       "top           4\n",
       "freq       7859\n",
       "Name: educ, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Education - set as ordered categories\n",
    "educ = survey.Q4.copy()\n",
    "educ[survey.Q4=='No formal education past high school'] = 1\n",
    "educ[survey.Q4==\"Bachelor’s degree\"] = 3\n",
    "educ[survey.Q4==\"Master’s degree\"] = 4\n",
    "educ[survey.Q4==\"Doctoral degree\"] = 5\n",
    "educ[survey.Q4==\"Professional degree\"] = 5\n",
    "educ[survey.Q4==\"Some college/university study without earning a bachelor’s degree\"] = 2\n",
    "educ[survey.Q4==\"I prefer not to answer\"] = None\n",
    "educ =educ.rename('educ')\n",
    "print(\"Education Levels: 1-HS or less 2=Some College 3=BA 4=MA 5=PhD\")\n",
    "print(educ.value_counts())\n",
    "print(type(educ))\n",
    "educ.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Experience (Years) - Range Mid Points\n",
      "4.0     4546\n",
      "1.5     4505\n",
      "0.5     3313\n",
      "7.5     2552\n",
      "15.0    1751\n",
      "25.0    1329\n",
      "0.0     1124\n",
      "Name: prog_exp, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     19120.0\n",
       "unique        7.0\n",
       "top           4.0\n",
       "freq       4546.0\n",
       "Name: prog_exp, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Programming Experience - set as ordered category\n",
    "prog_exp = survey.Q6.copy()\n",
    "prog_exp[survey.Q6=='I have never written code'] = 0\n",
    "prog_exp[survey.Q6=='< 1 years'] = 0.5\n",
    "prog_exp[survey.Q6=='1-2 years'] = 1.5\n",
    "prog_exp[survey.Q6=='2-3 years'] = 2.5\n",
    "prog_exp[survey.Q6=='3-5 years'] = 4\n",
    "prog_exp[survey.Q6=='5-10 years'] = 7.5\n",
    "prog_exp[survey.Q6=='10-20 years'] = 15\n",
    "prog_exp[survey.Q6=='20+ years'] = 25\n",
    "prog_exp = prog_exp.rename('prog_exp')\n",
    "print(\"Programming Experience (Years) - Range Mid Points\")\n",
    "print(prog_exp.value_counts())\n",
    "prog_exp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colind(var,column_names, title):\n",
    "    \"\"\"\n",
    "    This function extract from the survey file all columns corresponding to a question, and re-codes to \n",
    "    get indicator columns.\n",
    "    \"\"\"\n",
    "    _cnames = [n for n in survey.columns if str(n).find(var)!=-1]\n",
    "    _selected = survey[_cnames].copy()\n",
    "    for col in _cnames:\n",
    "        _selected[col][_selected[col].isna()]=0\n",
    "        _selected[col][_selected[col]!=0]=1\n",
    "    _selected.columns = column_names\n",
    "    print(title)\n",
    "    print(_selected.describe())\n",
    "    type(_selected)\n",
    "    return _selected \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebooks Used Regularly\n",
      "        Kaggle  Colab  Azure  Paperspace_Gradient  Binder_JupyterHub  \\\n",
      "count    20036  20036  20036                20036              20036   \n",
      "unique       2      2      2                    2                  2   \n",
      "top          0      0      0                    0                  0   \n",
      "freq     14044  13707  19179                19856              17964   \n",
      "\n",
      "        Code_Ocean  IBMWatson_Studio  Amazon_SagenmakerStudio  Amazon_EMR  \\\n",
      "count        20036             20036                    20036       20036   \n",
      "unique           2                 2                        2           2   \n",
      "top              0                 0                        0           0   \n",
      "freq         19931             19190                    19539       19791   \n",
      "\n",
      "        Google_Cloud_AIPlatform  Google_Cloud_Datalab  Databricks  \\\n",
      "count                     20036                 20036       20036   \n",
      "unique                        2                     2           2   \n",
      "top                           0                     0           0   \n",
      "freq                      18818                 18805       19642   \n",
      "\n",
      "        No_notebook  Other_notebook  \n",
      "count         20036           20036  \n",
      "unique            2               2  \n",
      "top               0               0  \n",
      "freq          14754           19551  \n",
      "Specialized Hardware Used Regularly\n",
      "         GPUs   TPUs   None  Other\n",
      "count   20036  20036  20036  20036\n",
      "unique      2      2      2      2\n",
      "top         0      0      0      0\n",
      "freq    11726  19076  12145  19370\n",
      "ML Frameworks Used Regularly\n",
      "        Scikit-learn  TensorFlow  Keras  Pytorch  Fast.ai  MXNet  Xgboost  \\\n",
      "count          20036       20036  20036    20036    20036  20036    20036   \n",
      "unique             2           2      2        2        2      2        2   \n",
      "top                1           0      0        0        0      0        0   \n",
      "freq           10250       13102  13844    15847    19294  19818    16101   \n",
      "\n",
      "        LightGBM  CatBoot  Prophet  H2O_3  Caret  Tidymodels    JAX  \\\n",
      "count      20036    20036    20036  20036  20036       20036  20036   \n",
      "unique         2        2        2      2      2           2      2   \n",
      "top            0        0        0      0      0           0      0   \n",
      "freq       18237    19079    19504  19692  19097       19552  19952   \n",
      "\n",
      "        No_MLFrame  Other_MLFrame  \n",
      "count        20036          20036  \n",
      "unique           2              2  \n",
      "top              0              0  \n",
      "freq         18828          19665  \n",
      "ML Algorithms Used Regularly\n",
      "        Linear Logistic Reg  Decision Trees Random Forest  \\\n",
      "count                 20036                         20036   \n",
      "unique                    2                             2   \n",
      "top                       1                             0   \n",
      "freq                  10560                         11232   \n",
      "\n",
      "        Gradient Boosting Machines  Bayesian Approaches  \\\n",
      "count                        20036                20036   \n",
      "unique                           2                    2   \n",
      "top                              0                    0   \n",
      "freq                         14902                16389   \n",
      "\n",
      "        Evolucionary Aproaches  Dense Neural Networks  \\\n",
      "count                    20036                  20036   \n",
      "unique                       2                      2   \n",
      "top                          0                      0   \n",
      "freq                     19305                  16672   \n",
      "\n",
      "        Convolutional Neural Networks  Generative Adversarial Networks  \\\n",
      "count                           20036                            20036   \n",
      "unique                              2                                2   \n",
      "top                                 0                                0   \n",
      "freq                            14177                            19012   \n",
      "\n",
      "        Recurrent Neural Networks  Transformer Networks  No_MLAlg  Other_MLAlg  \n",
      "count                       20036                 20036     20036        20036  \n",
      "unique                          2                     2         2            2  \n",
      "top                             0                     0         0            0  \n",
      "freq                        16568                 18738     19300        19626  \n",
      "Computer Vision Methods Used Regularly\n",
      "        General Purpose Image/Video Tools  Image Segmentation Methods  \\\n",
      "count                               20036                       20036   \n",
      "unique                                  2                           2   \n",
      "top                                     0                           0   \n",
      "freq                                17897                       18033   \n",
      "\n",
      "        Object Detection Methods  Image_Classification  Generative Networks  \\\n",
      "count                      20036                 20036                20036   \n",
      "unique                         2                     2                    2   \n",
      "top                            0                     0                    0   \n",
      "freq                       17957                 16524                18944   \n",
      "\n",
      "        No_CompVMeth  Other_CompVMeth  \n",
      "count          20036            20036  \n",
      "unique             2                2  \n",
      "top                0                0  \n",
      "freq           18883            19965  \n",
      "NLP Methods Used Regularly\n",
      "        Word Embeddings/vectors  Encoder-decoder models  \\\n",
      "count                     20036                   20036   \n",
      "unique                        2                       2   \n",
      "top                           0                       0   \n",
      "freq                      17926                   18522   \n",
      "\n",
      "        Contextualized Embeddings  Transformer Language Models  No_NLPMeth  \\\n",
      "count                       20036                        20036       20036   \n",
      "unique                          2                            2           2   \n",
      "top                             0                            0           0   \n",
      "freq                        19479                        18608       18989   \n",
      "\n",
      "        Other_NLPMeth  \n",
      "count           20036  \n",
      "unique              2  \n",
      "top                 0  \n",
      "freq            19954  \n"
     ]
    }
   ],
   "source": [
    "# Question 10 - Which hosted notebook products do you use on a regular basis?\n",
    "nbcols = ['Kaggle','Colab','Azure','Paperspace_Gradient','Binder_JupyterHub','Code_Ocean','IBMWatson_Studio','Amazon_SagenmakerStudio','Amazon_EMR','Google_Cloud_AIPlatform','Google_Cloud_Datalab','Databricks','No_notebook','Other_notebook']\n",
    "notebooks = colind('Q10', nbcols, \"Notebooks Used Regularly\")\n",
    "\n",
    "# Question 12 - What specialized hardward do you use on a regular basis?\n",
    "hcols = ['GPUs','TPUs','None','Other']\n",
    "hardware = colind('Q12', hcols, \"Specialized Hardware Used Regularly\")\n",
    "\n",
    "# Question 16 - Which ML frameworks do you use on a regular basis?\n",
    "mlfcols = ['Scikit-learn','TensorFlow','Keras','Pytorch','Fast.ai','MXNet', 'Xgboost','LightGBM', 'CatBoot','Prophet', 'H2O_3','Caret','Tidymodels','JAX','No_MLFrame','Other_MLFrame']\n",
    "mlframe = colind('Q16', mlfcols, \"ML Frameworks Used Regularly\")\n",
    "\n",
    "# Question 17 - Which ML algorithm do you use on a regular basis?\n",
    "mlacols = ['Linear Logistic Reg','Decision Trees Random Forest','Gradient Boosting Machines', 'Bayesian Approaches', 'Evolucionary Aproaches','Dense Neural Networks','Convolutional Neural Networks','Generative Adversarial Networks','Recurrent Neural Networks','Transformer Networks', 'No_MLAlg', 'Other_MLAlg']\n",
    "mlalgor = colind('Q17', mlacols, \"ML Algorithms Used Regularly\")\n",
    "\n",
    "# Question 18 - Which categories of computer vision methods do you use on a regular basis?\n",
    "cvmcols = ['General Purpose Image/Video Tools','Image Segmentation Methods','Object Detection Methods', 'Image_Classification' , 'Generative Networks', 'No_CompVMeth', 'Other_CompVMeth']\n",
    "cvisionm = colind('Q18', cvmcols, \"Computer Vision Methods Used Regularly\")\n",
    "\n",
    "# Question 19 - Which NLP method do you use on a regular basis?\n",
    "nlpmcols = ['Word Embeddings/vectors','Encoder-decoder models','Contextualized Embeddings','Transformer Language Models', 'No_NLPMeth', 'Other_NLPMeth']\n",
    "nlpm = colind('Q19', nlpmcols, \"NLP Methods Used Regularly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming Language Used Regularly\n",
      "        PL_Python   PL_R  PL_SQL   PL_C  PL_C++  PL_Java  PL_Javascript  \\\n",
      "count       20036  20036   20036  20036   20036    20036          20036   \n",
      "unique          2      2       2      2       2        2              2   \n",
      "top             1      0       0      0       0        0              0   \n",
      "freq        15530  15759   12501  16721   16209    16669          17041   \n",
      "\n",
      "        PL_Julia  PL_Swift  PL_Bash  PL_MATLAB  PL_None  PL_Other  \n",
      "count      20036     20036    20036      20036    20036     20036  \n",
      "unique         2         2        2          2        2         2  \n",
      "top            0         0        0          0        0         0  \n",
      "freq       19774     19838    18260      17819    19830     18091  \n"
     ]
    }
   ],
   "source": [
    "# Question 8 - What languages do you use on a regular basis?\n",
    "plcols =['PL_Python','PL_R','PL_SQL','PL_C','PL_C++','PL_Java','PL_Javascript','PL_Julia','PL_Swift','PL_Bash','PL_MATLAB','PL_None','PL_Other']\n",
    "proglan = colind('Q7', plcols, \"Programming Language Used Regularly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Programming Languages Used\n",
      "2     5112\n",
      "1     4252\n",
      "3     4103\n",
      "0     2334\n",
      "4     2165\n",
      "5     1165\n",
      "6      557\n",
      "7      220\n",
      "8       86\n",
      "9       26\n",
      "10       9\n",
      "11       4\n",
      "12       3\n",
      "Name: Language Number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of programming languages\n",
    "q7cols = [n for n in survey.columns if str(n).find('Q7')!=-1]\n",
    "n_lang = pd.Series([sum(row[q7cols].notna()) for i, row in survey.iterrows() if not('None' in row[q7cols])])\n",
    "n_lang[survey.Q7_Part_12=='None'] = 0\n",
    "n_lang = n_lang.rename('Language Number')\n",
    "\n",
    "print(\"Number of Programming Languages Used\")\n",
    "print(n_lang.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Male            15789\n",
      "Woman            3878\n",
      "Gender_Other      369\n",
      "Name: gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Gender\n",
    "gender = survey.Q2.copy()\n",
    "gender[survey.Q2=='Man'] = 'Male'\n",
    "gender[survey.Q2=='Woman'] = 'Woman'\n",
    "gender[survey.Q2=='Nonbinary']= 'Gender_Other'\n",
    "gender[survey.Q2=='Prefer not to say'] = 'Gender_Other'\n",
    "gender[survey.Q2=='Prefer to self-describe'] = 'Gender_Other'\n",
    "gender = gender.rename('gender')\n",
    "\n",
    "print(\"Gender\")\n",
    "print(gender.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of Data Visualizatio Libraries\n",
      "True     16478\n",
      "False     3558\n",
      "Name: vizlib, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use of data visialization libraries (python, R, Javascript)\n",
    "xv = [n for n in survey.columns if str(n).find('Q14')!=-1]\n",
    "vizlib = pd.Series([any(row[xv].notna()) and not('None' in row[xv]) for i, row in survey.iterrows()])\n",
    "vizlib = vizlib.rename('vizlib')\n",
    "print(\"Use of Data Visualizatio Libraries\")\n",
    "print(vizlib.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Algorithm Experience\n",
      "Some ML Experience       9771\n",
      "More than 2yrs ML Exp    4528\n",
      "No ML Experience         2075\n",
      "Name: mlexp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning methods: 2 or more years of experience, some experience or none\n",
    "mlexp = pd.Series(survey.Q15.copy())\n",
    "mlexp[survey.Q15=='I do not use machine learning methods'] = 'No ML Experience'\n",
    "mlexp[survey.Q15=='Under 1 year'] = 'Some ML Experience'\n",
    "mlexp[survey.Q15=='1-2 years'] = 'Some ML Experience'\n",
    "mlexp[survey.Q15=='2-3 years'] = 'More than 2yrs ML Exp'\n",
    "mlexp[survey.Q15=='3-4 years'] = 'More than 2yrs ML Exp'\n",
    "mlexp[survey.Q15=='4-5 years'] = 'More than 2yrs ML Exp'\n",
    "mlexp[survey.Q15=='5-10 years'] = 'More than 2yrs ML Exp'\n",
    "mlexp[survey.Q15=='10-20 years'] = 'More than 2yrs ML Exp'\n",
    "mlexp[survey.Q15=='20 or more years'] = 'More than 2yrs ML Exp'\n",
    "mlexp = mlexp.rename('mlexp')\n",
    "\n",
    "print(\"Machine Learning Algorithm Experience\")\n",
    "print(mlexp.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5     6312\n",
      "1.5     3459\n",
      "0.0     2075\n",
      "2.5     1631\n",
      "3.5      893\n",
      "7.5      801\n",
      "4.5      784\n",
      "15.0     244\n",
      "25.0     175\n",
      "Name: mlexp_or, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning Experience - ordered categories\n",
    "mlexp_or = survey.Q15.copy()\n",
    "mlexp_or[survey.Q15=='I do not use machine learning methods'] = 0\n",
    "mlexp_or[survey.Q15=='Under 1 year'] = 0.5\n",
    "mlexp_or[survey.Q15=='1-2 years'] = 1.5\n",
    "mlexp_or[survey.Q15=='2-3 years'] = 2.5\n",
    "mlexp_or[survey.Q15=='3-4 years'] = 3.5\n",
    "mlexp_or[survey.Q15=='4-5 years'] = 4.5\n",
    "mlexp_or[survey.Q15=='5-10 years'] = 7.5\n",
    "mlexp_or[survey.Q15=='10-20 years'] = 15\n",
    "mlexp_or[survey.Q15=='20 or more years'] = 25\n",
    "mlexp_or = mlexp_or.rename('mlexp_or')\n",
    "print(mlexp_or.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use of Cloud Computing\n",
      "False    13140\n",
      "True      6896\n",
      "Name: cloudcomp, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cloud computer use\n",
    "\n",
    "xcc = [n for n in survey.columns if str(n).find('Q26_A')!=-1]\n",
    "cloudcomp = pd.Series([any(row[xcc].notna()) and not('None' in row[xcc]) for i, row in survey.iterrows()])\n",
    "cloudcomp = cloudcomp.rename('cloudcomp')\n",
    "print(\"Use of Cloud Computing\")\n",
    "print(cloudcomp.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q24_lb_wage  Q24_ub_wage      wage\n",
      "0          NaN          NaN       NaN\n",
      "1     100000.0     124999.0  112499.5\n",
      "2      15000.0      19999.0   17499.5\n",
      "3     125000.0     149999.0  137499.5\n",
      "4          NaN          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "wage_df = survey.Q24.str.lstrip('> $').str.split('-',expand=True)\n",
    "wage_df = wage_df.replace(',','',regex=True).apply(pd.to_numeric, errors='coerce')\n",
    "wage_df.columns = ['Q24_lb_wage','Q24_ub_wage']\n",
    "wage_df['wage'] = wage_df['Q24_lb_wage']+(wage_df['Q24_ub_wage']-wage_df['Q24_lb_wage'])/2\n",
    "wage_df.wage[wage_df['Q24_lb_wage']==500000] = 600000\n",
    "print(wage_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country  medianHouseholdIncome CountryIncLev\n",
      "130        Togo                  571.0    Low Income\n",
      "129     Burundi                  673.0    Low Income\n",
      "128     Liberia                  781.0    Low Income\n",
      "127  Madagascar                 1013.0    Low Income\n",
      "126      Rwanda                 1101.0    Low Income\n"
     ]
    }
   ],
   "source": [
    "## Classify countries by medium wage quartiles\n",
    "\n",
    "incpath='C:\\\\Users\\\\l_gas\\\\Documents\\\\Data\\\\Countries Median Income\\\\'    \n",
    "country_inc = pd.read_json(incpath+\"data.json\")\n",
    "country_inc = country_inc[country_inc.medianHouseholdIncome.notna()]\n",
    "medinc=country_inc[[\"country\",\"medianHouseholdIncome\"]].sort_values(by=\"medianHouseholdIncome\")\n",
    "\n",
    "#sns.relplot(x=\"country\",y=\"medianHouseholdwage\",data=medinc)\n",
    "#plt.show()\n",
    "\n",
    "medinc=pd.concat([medinc,pd.qcut(medinc.medianHouseholdIncome,4,labels=[\"Low Income\",\"Medium Low Inc\", \"Medium High Inc\", \"High Income\"]).rename(\"CountryIncLev\")],axis=1)\n",
    "print(medinc.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20036, 127)\n"
     ]
    }
   ],
   "source": [
    "# CREATE FILE WITH SELECTED VARIABLES - INCLUDE ORDER CATEGORIES\n",
    "# Regular categories\n",
    "\n",
    "## Select categorical variables to create dummies\n",
    "rc = ['Q3','Q5','Q11','Q38','Q24']\n",
    "categories = survey[rc].copy()\n",
    "categories.Q3[categories.Q3=='Other'] = 'Other Countries'\n",
    "categories.Q3[categories.Q3=='United States of America'] = 'United States'\n",
    "categories.Q3[categories.Q3=='Iran, Islamic Republic of...'] = 'Iran'\n",
    "categories.Q3[categories.Q3=='United K ingdom of Great Britain and Northern Ireland'] = 'United Kingdom'\n",
    "\n",
    "## Country will be used to get 4 different wage levels based on median household wage in the country\n",
    "categories = categories.merge(medinc[['country','CountryIncLev']],how='left', left_on='Q3', right_on='country')\n",
    "\n",
    "## Top 10 countries with surveys will translate into an indicator column\n",
    "#top10 = [\"India\",\"United States\", \"Brazil\", \"Japan\",\"Russia\", \"United Kingdom\",\"Nigeria\",\"China\",\"Germany\",\"Turkey\"]\n",
    "top10 = [\"India\", \"United States\", \"Brazil\", \"Japan\", \"Russia\", \"United Kingdom\", \"Germany\", \"Nigeria\", \"Spain\", \"Canada\"]\n",
    "categories['TopCountries'] = \"Other\"\n",
    "for (i,c) in categories.country.items():\n",
    "    if c in top10:\n",
    "        categories.loc[i,'TopCountries'] = c\n",
    "\n",
    "# Final list of variables to create dummies and corresponding prefix\n",
    "rcnew = ['CountryIncLev','TopCountries','Q5','Q11','Q38']\n",
    "rc_n = ['Country','','Role','Platform','MainTool']\n",
    "\n",
    "xmc = pd.get_dummies(categories,columns=rcnew,prefix=rc_n)\n",
    "xmc = xmc.drop(['Q3','country'],axis=1)\n",
    "# Transformed regular categories\n",
    "xmc2 = pd.get_dummies(gender,columns=['gender'])\n",
    "xmc3 = pd.get_dummies(mlexp,columns=['mlexp'])\n",
    "\n",
    "categ2 = [age_lev, educ, prog_exp, notebooks, hardware, mlframe, mlalgor, cvisionm, nlpm, proglan, n_lang, mlexp_or, vizlib, cloudcomp, xmc, xmc2, xmc3,wage_df]\n",
    "\n",
    "features2 = pd.concat(categ2,axis=1)\n",
    "print(features2.shape)\n",
    "features2.to_json(\"./DS_ML_Survey_feature_sel_3.json\", compression=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age_lev', 'educ', 'prog_exp', 'Kaggle', 'Colab', 'Azure',\n",
      "       'Paperspace_Gradient', 'Binder_JupyterHub', 'Code_Ocean',\n",
      "       'IBMWatson_Studio', 'Amazon_SagenmakerStudio', 'Amazon_EMR',\n",
      "       'Google_Cloud_AIPlatform', 'Google_Cloud_Datalab', 'Databricks',\n",
      "       'No_notebook', 'Other_notebook', 'GPUs', 'TPUs', 'None', 'Other',\n",
      "       'Scikit-learn', 'TensorFlow', 'Keras', 'Pytorch', 'Fast.ai', 'MXNet',\n",
      "       'Xgboost', 'LightGBM', 'CatBoot', 'Prophet', 'H2O_3', 'Caret',\n",
      "       'Tidymodels', 'JAX', 'No_MLFrame', 'Other_MLFrame',\n",
      "       'Linear Logistic Reg', 'Decision Trees Random Forest',\n",
      "       'Gradient Boosting Machines', 'Bayesian Approaches',\n",
      "       'Evolucionary Aproaches', 'Dense Neural Networks',\n",
      "       'Convolutional Neural Networks', 'Generative Adversarial Networks',\n",
      "       'Recurrent Neural Networks', 'Transformer Networks', 'No_MLAlg',\n",
      "       'Other_MLAlg', 'General Purpose Image/Video Tools',\n",
      "       'Image Segmentation Methods', 'Object Detection Methods',\n",
      "       'Image_Classification', 'Generative Networks', 'No_CompVMeth',\n",
      "       'Other_CompVMeth', 'Word Embeddings/vectors', 'Encoder-decoder models',\n",
      "       'Contextualized Embeddings', 'Transformer Language Models',\n",
      "       'No_NLPMeth', 'Other_NLPMeth', 'PL_Python', 'PL_R', 'PL_SQL', 'PL_C',\n",
      "       'PL_C++', 'PL_Java', 'PL_Javascript', 'PL_Julia', 'PL_Swift', 'PL_Bash',\n",
      "       'PL_MATLAB', 'PL_None', 'PL_Other', 'Language Number', 'mlexp_or',\n",
      "       'vizlib', 'cloudcomp', 'Q24', 'Country_Low Income',\n",
      "       'Country_Medium Low Inc', 'Country_Medium High Inc',\n",
      "       'Country_High Income', '_Brazil', '_Canada', '_Germany', '_India',\n",
      "       '_Japan', '_Nigeria', '_Other', '_Russia', '_Spain', '_United States',\n",
      "       'Role_Business Analyst', 'Role_Currently not employed',\n",
      "       'Role_DBA/Database Engineer', 'Role_Data Analyst', 'Role_Data Engineer',\n",
      "       'Role_Data Scientist', 'Role_Machine Learning Engineer', 'Role_Other',\n",
      "       'Role_Product/Project Manager', 'Role_Research Scientist',\n",
      "       'Role_Software Engineer', 'Role_Statistician', 'Role_Student',\n",
      "       'Platform_A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)',\n",
      "       'Platform_A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)',\n",
      "       'Platform_A personal computer or laptop', 'Platform_None',\n",
      "       'Platform_Other',\n",
      "       'MainTool_Advanced statistical software (SPSS, SAS, etc.)',\n",
      "       'MainTool_Basic statistical software (Microsoft Excel, Google Sheets, etc.)',\n",
      "       'MainTool_Business intelligence software (Salesforce, Tableau, Spotfire, etc.)',\n",
      "       'MainTool_Cloud-based data software & APIs (AWS, GCP, Azure, etc.)',\n",
      "       'MainTool_Local development environments (RStudio, JupyterLab, etc.)',\n",
      "       'MainTool_Other', 'Gender_Other', 'Male', 'Woman',\n",
      "       'More than 2yrs ML Exp', 'No ML Experience', 'Some ML Experience',\n",
      "       'Q24_lb_wage', 'Q24_ub_wage', 'wage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(features2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
